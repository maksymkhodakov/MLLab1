# Лабораторна робота №1 
# з дисципліни "Машинне навчання"
# студента групи ШІ Ходакова Максима Олеговича

### Dataset: https://www.kaggle.com/datasets/yasserh/wine-quality-dataset/data
```
ЛІНІЙНА РЕГРЕСІЯ (OLS/Ridge/Lasso) ДЛЯ ПРОГНОЗУВАННЯ 'alcohol' В ДАТАСЕТІ WineQT
-------------------------------------------------------------------------------

Ціль: побудувати регресійну модель, яка **передбачає неперервну величину** 'alcohol'
за іншими ознаками (fixed acidity, sulphates, тощо).

Чому не 'quality'?
- 'quality' у WineQT — дискретна змінна (0..10). Для демонстрації **лінійної регресії**
  коректніше обрати **справді неперервну** ціль. Тому беремо 'alcohol'.

Моделі:
- OLS (Ordinary Least Squares) — без штрафів
- Ridge (L2-регуляризація) — зменшує всі коефіцієнти плавно
- Lasso (L1-регуляризація) — може занулювати деякі коефіцієнти (відбір ознак)

Ключові формули (коротко, у позначеннях):
------------------------------------------
Нехай X ∈ R^{m×n} — матриця ознак (m прикладів, n ознак),
y ∈ R^{m} — вектор цілей, w ∈ R^{n} — коефіцієнти, b — зсув (intercept).
Передбачення: ŷ = Xw + b.

1) Функція втрат OLS (MSE — Mean Squared Error):
   MSE(w, b) = (1/m) * Σ_{i=1..m} (y_i - ŷ_i)^2
   Те ж для метрик:
   - MAE = (1/m) * Σ |y_i - ŷ_i|  (середня абсолютна похибка)
   - R² = 1 - SS_res / SS_tot, де:
         SS_res = Σ (y_i - ŷ_i)^2
         SS_tot = Σ (y_i - ȳ)^2, ȳ — середнє по y.
     Інтерпретація R²: частка варіації y, пояснена моделлю (чим ближче до 1 — тим краще).

2) Ridge (L2): мінімізує
   J_Ridge(w, b) = MSE(w, b) + α * ||w||_2^2 = MSE + α * Σ w_j^2
   Де α ≥ 0 — гіперпараметр штрафу. Великий α сильніше стискає w до нуля.

3) Lasso (L1): мінімізує
   J_Lasso(w, b) = MSE(w, b) + α * ||w||_1 = MSE + α * Σ |w_j|
   Може зануляти деякі w_j → вбудований відбір ознак.

4) Стандартизація ознак (для стабільності оптимізації):
   z = (x - μ) / σ, де μ — середнє по train, σ — стандартне відхилення по train.
   ВАЖЛИВО: fit μ,σ тільки на train → transform на val/test (уникаємо leakage).

Перевірка overfitting:
- Розбиваємо дані на **train/val/test = 60/20/20**.
- Дивимось розрив метрик між train та val (R²_gap, MAE_gap_rel).
- Малюємо **learning curve** (R² vs розмір train) і **validation curves** (R² vs α).
```
